{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2ba699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0fb69f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "265b1d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6633fd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The City of Lost Children</td>\n",
       "      <td>La Cité des Enfants Perdus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shanghai Triad</td>\n",
       "      <td>摇啊摇，摇到外婆桥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wings of Courage</td>\n",
       "      <td>Guillaumet, les ailes du courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>The Postman</td>\n",
       "      <td>Il postino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>The Confessional</td>\n",
       "      <td>Le confessionnal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45453</th>\n",
       "      <td>Mom</td>\n",
       "      <td>Maa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45455</th>\n",
       "      <td>St. Michael Had a Rooster</td>\n",
       "      <td>San Michele aveva un gallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>Subdue</td>\n",
       "      <td>رگ خواب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>Century of Birthing</td>\n",
       "      <td>Siglo ng Pagluluwal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>Satan Triumphant</td>\n",
       "      <td>Satana likuyushchiy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                    original_title\n",
       "28     The City of Lost Children        La Cité des Enfants Perdus\n",
       "29                Shanghai Triad                         摇啊摇，摇到外婆桥\n",
       "32              Wings of Courage  Guillaumet, les ailes du courage\n",
       "57                   The Postman                        Il postino\n",
       "58              The Confessional                  Le confessionnal\n",
       "...                          ...                               ...\n",
       "45453                        Mom                               Maa\n",
       "45455  St. Michael Had a Rooster        San Michele aveva un gallo\n",
       "45461                     Subdue                           رگ خواب\n",
       "45462        Century of Birthing               Siglo ng Pagluluwal\n",
       "45464           Satan Triumphant               Satana likuyushchiy\n",
       "\n",
       "[11402 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['title'] != df['original_title']][['title', 'original_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9cc33d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the necessary columns from the dataframe \n",
    "data = df[['title', 'overview', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64b01e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...  \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...  \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b225c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'id': 16, 'name': 'Animation'}, {'id': 35, '...\n",
       "1    [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...\n",
       "2    [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...\n",
       "3    [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...\n",
       "4                       [{'id': 35, 'name': 'Comedy'}]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "495f8e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 16, 'name': 'Animation'},\n",
       " {'id': 35, 'name': 'Comedy'},\n",
       " {'id': 10751, 'name': 'Family'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(data['genres'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4fa8dac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "45461    None\n",
       "45462    None\n",
       "45463    None\n",
       "45464    None\n",
       "45465    None\n",
       "Name: genres, Length: 45466, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres = dict()\n",
    "def add_ele_to_dict(ele_list):\n",
    "    ele_list = eval(ele_list)\n",
    "    for ele in ele_list:\n",
    "        if ele['name'] in all_genres:\n",
    "            all_genres[ele['name']] += 1\n",
    "        else:\n",
    "            all_genres[ele['name']] = 1\n",
    "            \n",
    "\n",
    "data['genres'].apply(lambda x: add_ele_to_dict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73f5c464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Animation': 1935,\n",
       " 'Comedy': 13182,\n",
       " 'Family': 2770,\n",
       " 'Adventure': 3496,\n",
       " 'Fantasy': 2313,\n",
       " 'Romance': 6735,\n",
       " 'Drama': 20265,\n",
       " 'Action': 6596,\n",
       " 'Crime': 4307,\n",
       " 'Thriller': 7624,\n",
       " 'Horror': 4673,\n",
       " 'History': 1398,\n",
       " 'Science Fiction': 3049,\n",
       " 'Mystery': 2467,\n",
       " 'War': 1323,\n",
       " 'Foreign': 1622,\n",
       " 'Music': 1598,\n",
       " 'Documentary': 3932,\n",
       " 'Western': 1042,\n",
       " 'TV Movie': 767,\n",
       " 'Carousel Productions': 1,\n",
       " 'Vision View Entertainment': 1,\n",
       " 'Telescene Film Group Productions': 1,\n",
       " 'Aniplex': 1,\n",
       " 'GoHands': 1,\n",
       " 'BROSTA TV': 1,\n",
       " 'Mardock Scramble Production Committee': 1,\n",
       " 'Sentai Filmworks': 1,\n",
       " 'Odyssey Media': 1,\n",
       " 'Pulser Productions': 1,\n",
       " 'Rogue State': 1,\n",
       " 'The Cartel': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c17a7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_genre = [genre for genre in all_genres if all_genres[genre] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c0fc1913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation',\n",
       " 'Comedy',\n",
       " 'Family',\n",
       " 'Adventure',\n",
       " 'Fantasy',\n",
       " 'Romance',\n",
       " 'Drama',\n",
       " 'Action',\n",
       " 'Crime',\n",
       " 'Thriller',\n",
       " 'Horror',\n",
       " 'History',\n",
       " 'Science Fiction',\n",
       " 'Mystery',\n",
       " 'War',\n",
       " 'Foreign',\n",
       " 'Music',\n",
       " 'Documentary',\n",
       " 'Western',\n",
       " 'TV Movie']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b2c07b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Animation', 'Comedy', 'Family', 'Adventure', 'Fantasy', 'Romance', 'Drama', 'Action', 'Crime', 'Thriller', 'Horror', 'History', 'Science Fiction', 'Mystery', 'War', 'Foreign', 'Music', 'Documentary', 'Western', 'TV Movie']\n"
     ]
    }
   ],
   "source": [
    "print(allowed_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b90196c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...  \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...  \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "853d1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first genre as the genre for the movie, \n",
    "# Converting the problem from multi-label to a multi-class problem. \n",
    "\n",
    "def getGenre(genre_list):\n",
    "    genre_list = eval(genre_list)\n",
    "    all_genre = []\n",
    "    if len(genre_list) > 0: \n",
    "        for ele in genre_list:\n",
    "            if ele['name'] in allowed_genre:\n",
    "                all_genre.append(ele['name'])\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    return ','.join(all_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7dddaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-97-bd8d73f94a7a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['genre'] = data['genres'].apply(lambda x: getGenre(x))\n"
     ]
    }
   ],
   "source": [
    "data['genre'] = data['genres'].apply(lambda x: getGenre(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aded16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['genre'].isin(allowed_genre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03b08055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c3159c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42321, 4)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8fc4490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>Animation,Comedy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>Adventure,Fantasy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>Romance,Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                              genres                     genre  \n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   Animation,Comedy,Family  \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  Adventure,Fantasy,Family  \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...            Romance,Comedy  \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...      Comedy,Drama,Romance  \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]                    Comedy  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5efbb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data[['title', 'overview', 'genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "579a1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('data/movies_metadata_filtered_multilabel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbeb7f",
   "metadata": {},
   "source": [
    "# Building and training a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf0a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b15779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/movies_metadata_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1c68fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview      genre  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  Animation  \n",
       "1  When siblings Judy and Peter discover an encha...  Adventure  \n",
       "2  A family wedding reignites the ancient feud be...    Romance  \n",
       "3  Cheated on, mistreated and stepped on, the wom...     Comedy  \n",
       "4  Just when George Banks has recovered from his ...     Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc66b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "int_encoding = label_encoder.fit_transform(data['genre'])\n",
    "int_encoding = int_encoding.reshape(len(int_encoding), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43181dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42321, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2b2d457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42321,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_encoding.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497d8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652411ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded = enc.fit_transform(int_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba9fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42321, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a726ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Animation'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the original class value back. \n",
    "label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aad46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5847e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tfidf = tfidf.fit_transform(data['overview'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "660809ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42321, 73186)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c945584",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_tfidf, int_encoding.reshape(-1), test_size = 0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6bd0c",
   "metadata": {},
   "source": [
    "### Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "673893c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ae97052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3946d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2004b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12697,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76079840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12697,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2163c84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5226"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test == test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ae0fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eec11f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab2cf54b50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ec7ae",
   "metadata": {},
   "source": [
    "### Trying out SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af55a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16a63489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c434b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6e800dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5703"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svm_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d9416",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92d62ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(solver='saga', random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d1f6d11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=13, solver='saga')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93fdf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pred = logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638382f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b3456c",
   "metadata": {},
   "source": [
    "## Trying a blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a1050d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc2a1eb34f0>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "from torchtext.legacy import data\n",
    " \n",
    "import random\n",
    "import spacy\n",
    "import re\n",
    " \n",
    "SEED=13\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "632621b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "71b387b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movies_metadata_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d1356b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview      genre  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  Animation  \n",
       "1  When siblings Judy and Peter discover an encha...  Adventure  \n",
       "2  A family wedding reignites the ancient feud be...    Romance  \n",
       "3  Cheated on, mistreated and stepped on, the wom...     Comedy  \n",
       "4  Just when George Banks has recovered from his ...     Comedy  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ef2e5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "counter = 0\n",
    "for genre in df['genre'].unique():\n",
    "    genre_dict[genre] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "99f0fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=spacy.load('en_core_web_sm')\n",
    " \n",
    "stop_words=spacy.lang.en.STOP_WORDS\n",
    " \n",
    " \n",
    "def spacy_token(x):\n",
    "  x= re.sub(r'[^a-zA-Z\\s]','',x)\n",
    "  x= re.sub(r'[\\n]',' ',x)\n",
    "  return [tok.text for tok in tokenizer.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0dc6f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(label):\n",
    "    ret = np.zeros(len(genre_dict), dtype=np.float32)\n",
    "    ret[genre_dict[label]] = 1.0\n",
    "#     ret = genre_dict[label]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1eb282a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT= data.Field(sequential=True,lower=True,tokenize=spacy_token, stop_words=stop_words, eos_token='EOS',include_lengths=True)\n",
    " \n",
    "LABEL=data.LabelField(sequential=False,use_vocab=False,preprocessing=label_processing, pad_token=None,unk_token=None)\n",
    " \n",
    "dataField=[(None,None),(\"overview\",TEXT),(\"genre\",LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "736138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TabularDataset(path='data/movies_metadata_filtered.csv', format='csv', fields=dataField, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0df4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data= dataset.split(split_ratio=0.8,random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3bb328b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [09:00, 1.59MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:12<00:00, 32568.95it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "TEXT.vocab.load_vectors('glove.6B.100d')\n",
    "embedding = TEXT.vocab.vectors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2aab366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(2*hidden_dim, label_size)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden,cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        \n",
    "        fc_output = self.fc(hidden)\n",
    "        outputs=self.act(fc_output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f15d3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(SimpleLSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = False, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, label_size)\n",
    "        self.act = nn.Softmax(dim = 1)\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden,cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        hidden = hidden.squeeze(dim=0)\n",
    "        hidden = self.dropout(hidden)\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        outputs=self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8e6b1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(AttentionLSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = False, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, label_size)\n",
    "        self.act = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "\n",
    "        \"\"\" \n",
    "        Now we will incorporate Attention mechanism in our LSTM model. In this new model, we will use attention to compute soft alignment score corresponding\n",
    "        between each of the hidden_state and the last hidden_state of the LSTM. We will be using torch.bmm for the batch matrix multiplication.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "\n",
    "        lstm_output : Final output of the LSTM which contains hidden layer outputs for each sequence.\n",
    "        final_state : Final time-step hidden state (h_n) of the LSTM\n",
    "\n",
    "        ---------\n",
    "\n",
    "        Returns : It performs attention mechanism by first computing weights for each of the sequence present in lstm_output and and then finally computing the\n",
    "                  new hidden state.\n",
    "\n",
    "        Tensor Size :\n",
    "                    hidden.size() = (batch_size, hidden_size)\n",
    "                    attn_weights.size() = (batch_size, num_seq)\n",
    "                    soft_attn_weights.size() = (batch_size, num_seq)\n",
    "                    new_hidden_state.size() = (batch_size, hidden_size)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        hidden = final_state.squeeze(0)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        attn_output = self.attention_net(packed_outputs, hidden)\n",
    "        \n",
    "        hidden = attn_output.squeeze(dim=0)\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        outputs=self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "22b3813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "nlabel = len(genre_dict)\n",
    "hidden_dim = 128\n",
    "learning_rate = 0.001\n",
    "dropout = 0.2\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.overview),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3441b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(\n",
    "    embedding_dim=embedding.shape[1], \n",
    "    hidden_dim=hidden_dim, \n",
    "    label_size=nlabel, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    embedding_weights=embedding, \n",
    "    dropout=dropout\n",
    ")\n",
    "model = model.to(device)\n",
    " \n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.01)\n",
    "loss_function = nn.BCELoss()\n",
    " \n",
    "def model_accuracy(predict,y):\n",
    "  true_predict= (predict.argmax(1)==y.argmax(1)).float()\n",
    "  acc=true_predict.sum()/len(true_predict)\n",
    " \n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "339f89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:: Epoch: 0, Loss: 0.15431635824014556, Accuracy: 0.32757710454598915\n",
      "Validation:: Epoch: 0, Loss: 0.14155593158593818, Accuracy: 0.39365671641791045\n",
      "\n",
      "Train:: Epoch: 1, Loss: 0.13977552697343645, Accuracy: 0.3999451197543234\n",
      "Validation:: Epoch: 1, Loss: 0.1359510511827113, Accuracy: 0.41079757462686567\n",
      "\n",
      "Train:: Epoch: 2, Loss: 0.1345477413456395, Accuracy: 0.4214708817455004\n",
      "Validation:: Epoch: 2, Loss: 0.13122706938145764, Accuracy: 0.43050373134328357\n",
      "\n",
      "Train:: Epoch: 3, Loss: 0.13104287478721366, Accuracy: 0.4384733309160988\n",
      "Validation:: Epoch: 3, Loss: 0.129612438825529, Accuracy: 0.43481809701492535\n",
      "\n",
      "Train:: Epoch: 4, Loss: 0.12874894915324336, Accuracy: 0.4479082002954663\n",
      "Validation:: Epoch: 4, Loss: 0.1281305810631211, Accuracy: 0.44846082089552236\n",
      "\n",
      "Train:: Epoch: 5, Loss: 0.12674446651395763, Accuracy: 0.45283336358250315\n",
      "Validation:: Epoch: 5, Loss: 0.12708069395218322, Accuracy: 0.44053171641791045\n",
      "\n",
      "Train:: Epoch: 6, Loss: 0.12486127977663616, Accuracy: 0.4648027032051446\n",
      "Validation:: Epoch: 6, Loss: 0.1258159208653578, Accuracy: 0.455107276119403\n",
      "\n",
      "Train:: Epoch: 7, Loss: 0.12317669132970414, Accuracy: 0.4719666182994843\n",
      "Validation:: Epoch: 7, Loss: 0.12588863975521344, Accuracy: 0.4572061567164179\n",
      "\n",
      "Train:: Epoch: 8, Loss: 0.12148622184429529, Accuracy: 0.4785363752886934\n",
      "Validation:: Epoch: 8, Loss: 0.1261415428190089, Accuracy: 0.456972947761194\n",
      "\n",
      "Train:: Epoch: 9, Loss: 0.11979489919711958, Accuracy: 0.4887967163661741\n",
      "Validation:: Epoch: 9, Loss: 0.12472489398362031, Accuracy: 0.4594216417910448\n",
      "\n",
      "Train:: Epoch: 10, Loss: 0.11812471935771546, Accuracy: 0.496731676358097\n",
      "Validation:: Epoch: 10, Loss: 0.12616246460533853, Accuracy: 0.4609375\n",
      "\n",
      "Train:: Epoch: 11, Loss: 0.11616939064466729, Accuracy: 0.5055438135030135\n",
      "Validation:: Epoch: 11, Loss: 0.12613792072481184, Accuracy: 0.45604011194029853\n",
      "\n",
      "Train:: Epoch: 12, Loss: 0.1142475444472061, Accuracy: 0.5136511248237682\n",
      "Validation:: Epoch: 12, Loss: 0.12811741933448992, Accuracy: 0.44834421641791045\n",
      "\n",
      "Train:: Epoch: 13, Loss: 0.11213419336193013, Accuracy: 0.5202798440771282\n",
      "Validation:: Epoch: 13, Loss: 0.12701693432989405, Accuracy: 0.46047108208955223\n",
      "\n",
      "Train:: Epoch: 14, Loss: 0.10979419224104792, Accuracy: 0.5358753629450528\n",
      "Validation:: Epoch: 14, Loss: 0.12856729639999903, Accuracy: 0.457089552238806\n",
      "\n",
      "Train:: Epoch: 15, Loss: 0.10762352038104579, Accuracy: 0.5458372642409127\n",
      "Validation:: Epoch: 15, Loss: 0.1288124722108912, Accuracy: 0.4532416044776119\n",
      "\n",
      "Train:: Epoch: 16, Loss: 0.10477178434156022, Accuracy: 0.5595718433272164\n",
      "Validation:: Epoch: 16, Loss: 0.13236338611858994, Accuracy: 0.44986007462686567\n",
      "\n",
      "Train:: Epoch: 17, Loss: 0.10202640820786638, Accuracy: 0.5741731677415236\n",
      "Validation:: Epoch: 17, Loss: 0.13527698759267578, Accuracy: 0.44029850746268656\n",
      "\n",
      "Train:: Epoch: 18, Loss: 0.09925470509619083, Accuracy: 0.5862917271425139\n",
      "Validation:: Epoch: 18, Loss: 0.13809783489846472, Accuracy: 0.43656716417910446\n",
      "\n",
      "Train:: Epoch: 19, Loss: 0.09584985257319684, Accuracy: 0.6012001089329989\n",
      "Validation:: Epoch: 19, Loss: 0.13806188362303065, Accuracy: 0.4380830223880597\n",
      "\n",
      "Train:: Epoch: 20, Loss: 0.09194928272715154, Accuracy: 0.6224256169121221\n",
      "Validation:: Epoch: 20, Loss: 0.14192654125726045, Accuracy: 0.43843283582089554\n",
      "\n",
      "Train:: Epoch: 21, Loss: 0.0884496454922658, Accuracy: 0.6347800254821777\n",
      "Validation:: Epoch: 21, Loss: 0.14500218407431645, Accuracy: 0.42922108208955223\n",
      "\n",
      "Train:: Epoch: 22, Loss: 0.08547467551422569, Accuracy: 0.6507578919518668\n",
      "Validation:: Epoch: 22, Loss: 0.14894626712176337, Accuracy: 0.42350746268656714\n",
      "\n",
      "Train:: Epoch: 23, Loss: 0.08186264861867112, Accuracy: 0.6675244920658615\n",
      "Validation:: Epoch: 23, Loss: 0.15319085410281794, Accuracy: 0.42723880597014924\n",
      "\n",
      "Train:: Epoch: 24, Loss: 0.07836202125785485, Accuracy: 0.6830066219815668\n",
      "Validation:: Epoch: 24, Loss: 0.15710698846560806, Accuracy: 0.4162779850746269\n",
      "\n",
      "Train:: Epoch: 25, Loss: 0.07498477354364574, Accuracy: 0.6982197932477268\n",
      "Validation:: Epoch: 25, Loss: 0.16328594333200314, Accuracy: 0.416044776119403\n",
      "\n",
      "Train:: Epoch: 26, Loss: 0.07169037611698205, Accuracy: 0.7102490022497358\n",
      "Validation:: Epoch: 26, Loss: 0.16447611842582474, Accuracy: 0.412196828358209\n",
      "\n",
      "Train:: Epoch: 27, Loss: 0.06845207255122797, Accuracy: 0.7265806423043305\n",
      "Validation:: Epoch: 27, Loss: 0.1732662587023493, Accuracy: 0.40893190298507465\n",
      "\n",
      "Train:: Epoch: 28, Loss: 0.0658402144065443, Accuracy: 0.7389912917928876\n",
      "Validation:: Epoch: 28, Loss: 0.179043572562844, Accuracy: 0.40496735074626866\n",
      "\n",
      "Train:: Epoch: 29, Loss: 0.06245439598020518, Accuracy: 0.7540543360530205\n",
      "Validation:: Epoch: 29, Loss: 0.18291198829216743, Accuracy: 0.4036847014925373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        (feature, batch_length), label = batch.overview, batch.genre\n",
    "        batch_length = batch_length.to('cpu')\n",
    "        label = label.float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(feature, batch_length) \n",
    "\n",
    "        loss = loss_function(output, label)\n",
    "        acc = model_accuracy(output,label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc+=acc.item() \n",
    "    print(f\"Train:: Epoch: {epoch}, Loss: {train_loss/len(train_iterator)}, Accuracy: {train_acc/len(train_iterator)}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0 \n",
    "    for i, batch in enumerate(valid_iterator):\n",
    "        (feature, batch_length), label = batch.overview, batch.genre\n",
    "        batch_length = batch_length.to('cpu')\n",
    "        label = label.float()\n",
    "\n",
    "        output = model(feature, batch_length) \n",
    "        loss = loss_function(output, label)\n",
    "        acc = model_accuracy(output,label)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_acc += acc.item() \n",
    "\n",
    "    print(f\"Validation:: Epoch: {epoch}, Loss: {val_loss/len(valid_iterator)}, Accuracy: {val_acc/len(valid_iterator)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "512ecc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'bi-lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a34d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('bi-lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "824af7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (word_embeddings): Embedding(75844, 50)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(50, 256, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=20, bias=True)\n",
       "  (act): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "848e9364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-407-9cc0ecb9eabe>:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(fc2_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.19567031202031604\n",
      "accuracy = 0.396571828358209\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    for i, batch in enumerate(valid_iterator):\n",
    "        (feature, batch_length), label = batch.overview, batch.genre\n",
    "        batch_length = batch_length.to('cpu')\n",
    "        label = label.float()\n",
    "#         print(feature, batch_length)\n",
    "        #             optimizer.zero_grad()\n",
    "        output = model(feature, batch_length) \n",
    "#         print(output.shape, label.shape)\n",
    "#         print(feature.shape, batch_length.shape)\n",
    "\n",
    "        loss = loss_function(output, label)\n",
    "        acc = model_accuracy(output,label)\n",
    "\n",
    "#         print(loss.item(), acc.item())\n",
    "\n",
    "        #             loss.backward()\n",
    "        #             optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item() \n",
    "\n",
    "    print(f\"loss = {total_loss/len(valid_iterator)}\")\n",
    "    print(f\"accuracy = {total_acc/len(valid_iterator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "351f7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Ram and shyam are two people living in australia. They marry love each other and live happily ever after.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "98e8ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vec = TEXT.preprocess(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e001c60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ram',\n",
       " 'shyam',\n",
       " 'people',\n",
       " 'living',\n",
       " 'australia',\n",
       " 'marry',\n",
       " 'love',\n",
       " 'live',\n",
       " 'happily']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "c149bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vec = [[TEXT.vocab.stoi[x] for x in sample_vec]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "57bf7805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9337, 16781, 32, 59, 2189, 320, 9, 66, 1756]]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a363deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vec_arr = np.asarray(sample_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "9ae81e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vec_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "398a5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vec_arr = torch.LongTensor(sample_vec_arr).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "fb348026",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vec_arr = sample_vec_arr.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "85b8ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vec_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a9ef6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tensor = torch.LongTensor([len(sample_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "19c868e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-358-9cc0ecb9eabe>:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs=self.act(fc2_output)\n"
     ]
    }
   ],
   "source": [
    "pred = model(sample_vec_arr, len_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "10f293df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d481e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Animation': 0,\n",
       " 'Adventure': 1,\n",
       " 'Romance': 2,\n",
       " 'Comedy': 3,\n",
       " 'Action': 4,\n",
       " 'Family': 5,\n",
       " 'History': 6,\n",
       " 'Drama': 7,\n",
       " 'Crime': 8,\n",
       " 'Fantasy': 9,\n",
       " 'Science Fiction': 10,\n",
       " 'Thriller': 11,\n",
       " 'Music': 12,\n",
       " 'Horror': 13,\n",
       " 'Documentary': 14,\n",
       " 'Mystery': 15,\n",
       " 'Western': 16,\n",
       " 'TV Movie': 17,\n",
       " 'War': 18,\n",
       " 'Foreign': 19}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee4410",
   "metadata": {},
   "source": [
    "### Multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6f9d20b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc2a1eb34f0>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "from torchtext.legacy import data\n",
    " \n",
    "import random\n",
    "import spacy\n",
    "import re\n",
    " \n",
    "SEED=13\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "74703041",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6db2a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movies_metadata_filtered_multilabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f10c9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Animation,Comedy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>Adventure,Fantasy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>Romance,Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview                     genre  \n",
       "0  Led by Woody, Andy's toys live happily in his ...   Animation,Comedy,Family  \n",
       "1  When siblings Judy and Peter discover an encha...  Adventure,Fantasy,Family  \n",
       "2  A family wedding reignites the ancient feud be...            Romance,Comedy  \n",
       "3  Cheated on, mistreated and stepped on, the wom...      Comedy,Drama,Romance  \n",
       "4  Just when George Banks has recovered from his ...                    Comedy  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9e1ae0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama                                           True\n",
       "Comedy                                          True\n",
       "Documentary                                     True\n",
       "Drama,Romance                                   True\n",
       "Comedy,Drama                                    True\n",
       "                                               ...  \n",
       "Science Fiction,Animation,Adventure,Fantasy    False\n",
       "Drama,War,Science Fiction                      False\n",
       "Comedy,Foreign,Adventure                       False\n",
       "Action,Drama,Horror,Crime,Thriller             False\n",
       "Thriller,Comedy,Crime,Adventure                False\n",
       "Name: genre, Length: 4044, dtype: bool"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts() > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff55d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "counter = 0\n",
    "for genre in allowed_genre:\n",
    "    genre_dict[genre] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "49598b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=spacy.load('en_core_web_sm')\n",
    " \n",
    "stop_words=spacy.lang.en.STOP_WORDS\n",
    " \n",
    " \n",
    "def spacy_token(x):\n",
    "  x= re.sub(r'[^a-zA-Z\\s]','',x)\n",
    "  x= re.sub(r'[\\n]',' ',x)\n",
    "  return [tok.text for tok in tokenizer.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb31baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(label):\n",
    "    ret = np.zeros(len(genre_dict), dtype=np.float32)\n",
    "    for ele in label.split(','):\n",
    "        ret[genre_dict[ele]] = 1.0\n",
    "#     ret = genre_dict[label]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "179cee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT= data.Field(sequential=True,lower=True,tokenize=spacy_token,eos_token='EOS',stop_words=stop_words,include_lengths=True)\n",
    " \n",
    "LABEL=data.LabelField(sequential=False,use_vocab=False,preprocessing=label_processing, pad_token=None,unk_token=None)\n",
    " \n",
    "dataField=[(None,None),(\"overview\",TEXT),(\"genre\",LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a528587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.TabularDataset(path='data/movies_metadata_filtered_multilabel.csv', format='csv', fields=dataField, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eec7d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data= dataset.split(split_ratio=0.8,random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce352412",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "TEXT.vocab.load_vectors('glove.6B.50d')\n",
    "embedding = TEXT.vocab.vectors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "876dedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(2*hidden_dim, label_size)\n",
    "        self.act = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden,cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        \n",
    "        fc_output = self.fc(hidden)\n",
    "        outputs=self.act(fc_output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "92969963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(SimpleLSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = False, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, label_size)\n",
    "        self.act = nn.Softmax(dim = 1)\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden,cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        hidden = hidden.squeeze(dim=0)\n",
    "        hidden = self.dropout(hidden)\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        outputs=self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "830d7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, dropout=0.2):\n",
    "        super(AttentionLSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            bidirectional = False, \n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, label_size)\n",
    "        self.act = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "\n",
    "        \"\"\" \n",
    "        Now we will incorporate Attention mechanism in our LSTM model. In this new model, we will use attention to compute soft alignment score corresponding\n",
    "        between each of the hidden_state and the last hidden_state of the LSTM. We will be using torch.bmm for the batch matrix multiplication.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "\n",
    "        lstm_output : Final output of the LSTM which contains hidden layer outputs for each sequence.\n",
    "        final_state : Final time-step hidden state (h_n) of the LSTM\n",
    "\n",
    "        ---------\n",
    "\n",
    "        Returns : It performs attention mechanism by first computing weights for each of the sequence present in lstm_output and and then finally computing the\n",
    "                  new hidden state.\n",
    "\n",
    "        Tensor Size :\n",
    "                    hidden.size() = (batch_size, hidden_size)\n",
    "                    attn_weights.size() = (batch_size, num_seq)\n",
    "                    soft_attn_weights.size() = (batch_size, num_seq)\n",
    "                    new_hidden_state.size() = (batch_size, hidden_size)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        hidden = final_state.squeeze(0)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    " \n",
    "    def forward(self, sentence, src_len, train = True):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeds, src_len)\n",
    "\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        \n",
    "        attn_output = self.attention_net(packed_outputs, hidden)\n",
    "        \n",
    "        hidden = attn_output.squeeze(dim=0)\n",
    "        \n",
    "        hidden = self.dropout(hidden)\n",
    "        dense_outputs = self.fc(hidden)\n",
    "        outputs=self.act(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a5bbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "nlabel = len(genre_dict)\n",
    "hidden_dim = 128\n",
    "learning_rate = 0.001\n",
    "dropout = 0.3\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.overview),\n",
    "    sort_within_batch=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a73b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(\n",
    "    embedding_dim=embedding.shape[1], \n",
    "    hidden_dim=hidden_dim, \n",
    "    label_size=nlabel, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    embedding_weights=embedding, \n",
    "    dropout=dropout\n",
    ")\n",
    "model = model.to(device)\n",
    " \n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_function = nn.BCELoss()\n",
    " \n",
    "def model_accuracy(predict,y):\n",
    "  true_predict= (predict.argmax(1)==y.argmax(1)).float()\n",
    "  acc=true_predict.sum()/len(true_predict)\n",
    " \n",
    "  return acc\n",
    "\n",
    "\n",
    "def multilabel_accuracy(predict, y, threshold = 0.6):    \n",
    "    predictions = torch.where(predict > threshold, 1.0, 0.0).float()\n",
    "\n",
    "    intersection = torch.where(predictions + y > 1, 1.0, 0.0)\n",
    "    union = torch.where(predictions + y >= 1, 1.0, 0.0)\n",
    "    acc = intersection.sum()/union.sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "977598ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_accuracy(torch.tensor([0.87, 0.24, 0.3]), torch.tensor([[1,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "129e0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:: Epoch: 0, Loss: 0.057634812396652295, Accuracy: 0.6076423761979589\n",
      "Validation:: Epoch: 0, Loss: 0.18616692632881562, Accuracy: 0.21915652791955578\n",
      "\n",
      "Train:: Epoch: 1, Loss: 0.05502048965613797, Accuracy: 0.6231977794530257\n",
      "Validation:: Epoch: 1, Loss: 0.19663861772017693, Accuracy: 0.23078933358192444\n",
      "\n",
      "Train:: Epoch: 2, Loss: 0.052276486432496105, Accuracy: 0.6442790275474765\n",
      "Validation:: Epoch: 2, Loss: 0.19978054156943933, Accuracy: 0.23130823560615085\n",
      "\n",
      "Train:: Epoch: 3, Loss: 0.050222306853195404, Accuracy: 0.6575803283250556\n",
      "Validation:: Epoch: 3, Loss: 0.20285056397986057, Accuracy: 0.22607200759560314\n",
      "\n",
      "Train:: Epoch: 4, Loss: 0.04916170597216993, Accuracy: 0.6649123142350395\n",
      "Validation:: Epoch: 4, Loss: 0.20981749225018628, Accuracy: 0.23369305525253067\n",
      "\n",
      "Train:: Epoch: 5, Loss: 0.04752675617500296, Accuracy: 0.6763206001722588\n",
      "Validation:: Epoch: 5, Loss: 0.21566741835715167, Accuracy: 0.22132272150979113\n",
      "\n",
      "Train:: Epoch: 6, Loss: 0.05096216631947823, Accuracy: 0.6489277862152963\n",
      "Validation:: Epoch: 6, Loss: 0.22110965114031264, Accuracy: 0.23318323581966002\n",
      "\n",
      "Train:: Epoch: 7, Loss: 0.04376300976102082, Accuracy: 0.7012858478528149\n",
      "Validation:: Epoch: 7, Loss: 0.22293075407618906, Accuracy: 0.2303264501379497\n",
      "\n",
      "Train:: Epoch: 8, Loss: 0.04078673576268385, Accuracy: 0.7198155379520272\n",
      "Validation:: Epoch: 8, Loss: 0.2321582051800258, Accuracy: 0.23343971972145253\n",
      "\n",
      "Train:: Epoch: 9, Loss: 0.03882056845808929, Accuracy: 0.7344102567096926\n",
      "Validation:: Epoch: 9, Loss: 0.24190866880452455, Accuracy: 0.2343079618998428\n",
      "\n",
      "Train:: Epoch: 10, Loss: 0.03656873477376857, Accuracy: 0.7496918786246821\n",
      "Validation:: Epoch: 10, Loss: 0.24543805931931112, Accuracy: 0.22688952199558712\n",
      "\n",
      "Train:: Epoch: 11, Loss: 0.03658033622745073, Accuracy: 0.7501112642153254\n",
      "Validation:: Epoch: 11, Loss: 0.24637496315721255, Accuracy: 0.2261215608511398\n",
      "\n",
      "Train:: Epoch: 12, Loss: 0.0352988730061729, Accuracy: 0.7583013947279948\n",
      "Validation:: Epoch: 12, Loss: 0.25422417539269176, Accuracy: 0.23030922995574438\n",
      "\n",
      "Train:: Epoch: 13, Loss: 0.03586975478760476, Accuracy: 0.7525318741798401\n",
      "Validation:: Epoch: 13, Loss: 0.2582232389432281, Accuracy: 0.22350590309100365\n",
      "\n",
      "Train:: Epoch: 14, Loss: 0.0345340213193646, Accuracy: 0.7642524704618274\n",
      "Validation:: Epoch: 14, Loss: 0.2570453197208803, Accuracy: 0.22877411299677036\n",
      "\n",
      "Train:: Epoch: 15, Loss: 0.030613992278868296, Accuracy: 0.7895359796173168\n",
      "Validation:: Epoch: 15, Loss: 0.27594256089694463, Accuracy: 0.23599656771368055\n",
      "\n",
      "Train:: Epoch: 16, Loss: 0.03051123882310008, Accuracy: 0.7879961003672402\n",
      "Validation:: Epoch: 16, Loss: 0.26971362931514853, Accuracy: 0.22352421795254324\n",
      "\n",
      "Train:: Epoch: 17, Loss: 0.03118121336864413, Accuracy: 0.7836420299871912\n",
      "Validation:: Epoch: 17, Loss: 0.2765457659070171, Accuracy: 0.22984387603268694\n",
      "\n",
      "Train:: Epoch: 18, Loss: 0.03322842722793795, Accuracy: 0.7692516873467643\n",
      "Validation:: Epoch: 18, Loss: 0.27378471551546407, Accuracy: 0.22943727160567667\n",
      "\n",
      "Train:: Epoch: 19, Loss: 0.027477754026932536, Accuracy: 0.8075608518888365\n",
      "Validation:: Epoch: 19, Loss: 0.2837576379082096, Accuracy: 0.2285810582228561\n",
      "\n",
      "Train:: Epoch: 20, Loss: 0.026007803926630966, Accuracy: 0.8188120132347323\n",
      "Validation:: Epoch: 20, Loss: 0.29094169411196635, Accuracy: 0.22934390270887917\n",
      "\n",
      "Train:: Epoch: 21, Loss: 0.02800983341656766, Accuracy: 0.8075670827109859\n",
      "Validation:: Epoch: 21, Loss: 0.2809461984616607, Accuracy: 0.22462211816168542\n",
      "\n",
      "Train:: Epoch: 22, Loss: 0.02744883796867897, Accuracy: 0.8055733806682083\n",
      "Validation:: Epoch: 22, Loss: 0.2909352356818185, Accuracy: 0.22536653146814944\n",
      "\n",
      "Train:: Epoch: 23, Loss: 0.02537857534117856, Accuracy: 0.8200927468965639\n",
      "Validation:: Epoch: 23, Loss: 0.2979445484147143, Accuracy: 0.22598820168580583\n",
      "\n",
      "Train:: Epoch: 24, Loss: 0.024610146732544, Accuracy: 0.8255216520912242\n",
      "Validation:: Epoch: 24, Loss: 0.30210558603059, Accuracy: 0.2233526817898252\n",
      "\n",
      "Train:: Epoch: 25, Loss: 0.02447663498515228, Accuracy: 0.8270355708194229\n",
      "Validation:: Epoch: 25, Loss: 0.31454794153348725, Accuracy: 0.2278447322436233\n",
      "\n",
      "Train:: Epoch: 26, Loss: 0.02499634817172334, Accuracy: 0.8242602630606237\n",
      "Validation:: Epoch: 26, Loss: 0.3218442348401938, Accuracy: 0.22956029737173622\n",
      "\n",
      "Train:: Epoch: 27, Loss: 0.022814499393527237, Accuracy: 0.839908946460148\n",
      "Validation:: Epoch: 27, Loss: 0.3186385489221829, Accuracy: 0.2288354942158087\n",
      "\n",
      "Train:: Epoch: 28, Loss: 0.021156842869548304, Accuracy: 0.8536272795695179\n",
      "Validation:: Epoch: 28, Loss: 0.32465028184563366, Accuracy: 0.22780677476036015\n",
      "\n",
      "Train:: Epoch: 29, Loss: 0.022905815635227932, Accuracy: 0.8411849624705765\n",
      "Validation:: Epoch: 29, Loss: 0.32500861740824, Accuracy: 0.22854573112815174\n",
      "\n",
      "Train:: Epoch: 30, Loss: 0.02448928271121574, Accuracy: 0.8261156957104521\n",
      "Validation:: Epoch: 30, Loss: 0.3183925774560046, Accuracy: 0.22049586852984643\n",
      "\n",
      "Train:: Epoch: 31, Loss: 0.022391448686567117, Accuracy: 0.8417004051073542\n",
      "Validation:: Epoch: 31, Loss: 0.3299216274450074, Accuracy: 0.22629829284860126\n",
      "\n",
      "Train:: Epoch: 32, Loss: 0.022898482696487095, Accuracy: 0.8384160620986291\n",
      "Validation:: Epoch: 32, Loss: 0.3250801914663457, Accuracy: 0.22853750813363202\n",
      "\n",
      "Train:: Epoch: 33, Loss: 0.022808439931217228, Accuracy: 0.8391288413191741\n",
      "Validation:: Epoch: 33, Loss: 0.3330673130590524, Accuracy: 0.23001970662109888\n",
      "\n",
      "Train:: Epoch: 34, Loss: 0.01810815197608943, Accuracy: 0.8736068569264321\n",
      "Validation:: Epoch: 34, Loss: 0.3389447233570156, Accuracy: 0.2252857447115343\n",
      "\n",
      "Train:: Epoch: 35, Loss: 0.01815426157928019, Accuracy: 0.8723295122947333\n",
      "Validation:: Epoch: 35, Loss: 0.34948447569092705, Accuracy: 0.22726521363009267\n",
      "\n",
      "Train:: Epoch: 36, Loss: 0.019008496449381674, Accuracy: 0.8638719527226574\n",
      "Validation:: Epoch: 36, Loss: 0.3411560772515055, Accuracy: 0.2217321235742142\n",
      "\n",
      "Train:: Epoch: 37, Loss: 0.018328533073852085, Accuracy: 0.8706132223021309\n",
      "Validation:: Epoch: 37, Loss: 0.35078877210617065, Accuracy: 0.22707426614725768\n",
      "\n",
      "Train:: Epoch: 38, Loss: 0.021686804793634506, Accuracy: 0.847185940337631\n",
      "Validation:: Epoch: 38, Loss: 0.3486750833134153, Accuracy: 0.22821849606820008\n",
      "\n",
      "Train:: Epoch: 39, Loss: 0.018610352818977157, Accuracy: 0.8677769559734273\n",
      "Validation:: Epoch: 39, Loss: 0.36664922023887064, Accuracy: 0.22831716755432868\n",
      "\n",
      "Train:: Epoch: 40, Loss: 0.01638417109882213, Accuracy: 0.8854822604161389\n",
      "Validation:: Epoch: 40, Loss: 0.35579308511605906, Accuracy: 0.22346240482223567\n",
      "\n",
      "Train:: Epoch: 41, Loss: 0.017331475107315576, Accuracy: 0.8762721047086536\n",
      "Validation:: Epoch: 41, Loss: 0.3659031729199993, Accuracy: 0.22736682931878674\n",
      "\n",
      "Train:: Epoch: 42, Loss: 0.01703495066612959, Accuracy: 0.8782224441474339\n",
      "Validation:: Epoch: 42, Loss: 0.3669943275736339, Accuracy: 0.22160441039213494\n",
      "\n",
      "Train:: Epoch: 43, Loss: 0.0158332873821118, Accuracy: 0.886775881389402\n",
      "Validation:: Epoch: 43, Loss: 0.374785992414204, Accuracy: 0.22172106669020297\n",
      "\n",
      "Train:: Epoch: 44, Loss: 0.01659065052199195, Accuracy: 0.8800002552428335\n",
      "Validation:: Epoch: 44, Loss: 0.3819097458426632, Accuracy: 0.22181639675773793\n",
      "\n",
      "Train:: Epoch: 45, Loss: 0.016324156596553775, Accuracy: 0.8838224165844467\n",
      "Validation:: Epoch: 45, Loss: 0.3745227878663077, Accuracy: 0.2241196260968251\n",
      "\n",
      "Train:: Epoch: 46, Loss: 0.016606617641617666, Accuracy: 0.881414942246563\n",
      "Validation:: Epoch: 46, Loss: 0.381001559211247, Accuracy: 0.22047616697069425\n",
      "\n",
      "Train:: Epoch: 47, Loss: 0.01745879802993446, Accuracy: 0.8766464015222946\n",
      "Validation:: Epoch: 47, Loss: 0.38366879567281525, Accuracy: 0.22396167601222422\n",
      "\n",
      "Train:: Epoch: 48, Loss: 0.014702935971952272, Accuracy: 0.8944338681562891\n",
      "Validation:: Epoch: 48, Loss: 0.38140991196703555, Accuracy: 0.21743609567186725\n",
      "\n",
      "Train:: Epoch: 49, Loss: 0.013232435760492423, Accuracy: 0.9058824579670745\n",
      "Validation:: Epoch: 49, Loss: 0.4002796238038077, Accuracy: 0.22655333867713587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        (feature, batch_length), label = batch.overview, batch.genre\n",
    "        batch_length = batch_length.to('cpu')\n",
    "        label = label.float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(feature, batch_length) \n",
    "\n",
    "        loss = loss_function(output, label)\n",
    "        acc = multilabel_accuracy(output,label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc.item() \n",
    "    print(f\"Train:: Epoch: {epoch}, Loss: {train_loss/len(train_iterator)}, Accuracy: {train_acc/len(train_iterator)}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0 \n",
    "    for i, batch in enumerate(valid_iterator):\n",
    "        (feature, batch_length), label = batch.overview, batch.genre\n",
    "        batch_length = batch_length.to('cpu')\n",
    "        label = label.float()\n",
    "\n",
    "        output = model(feature, batch_length) \n",
    "        loss = loss_function(output, label)\n",
    "        acc = multilabel_accuracy(output,label)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_acc += acc.item() \n",
    "\n",
    "    print(f\"Validation:: Epoch: {epoch}, Loss: {val_loss/len(valid_iterator)}, Accuracy: {val_acc/len(valid_iterator)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cadadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
